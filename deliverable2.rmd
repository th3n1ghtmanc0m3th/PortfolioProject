---
title: "deliverable2"
author: "Jay Gohner"
date: "November 21, 2019"
output: html_document
---

Step 2 scrape and organize data from https://www.ucrdatatool.gov/Search/Crime/State/RunCrimeStatebyState.cfm

Step 3 make prediction

Step 4 run tests

After gathering and cleaning data for adults rates of education from 1970 to 2000, we know focus on gathering data on
rates of violent crime for those same years. First we will pull in all our data from our previous project to  use for
this step of the project.

```{r}
suppressMessages(library("tidyverse"))
suppressMessages(library("knitr"))
purl("EduViolenceInsights.rmd", output = "part1.r") # produces r source from rmd
source("part1.r") # executes the source
```

I found a large xlsx from https://www.ucrdatatool.gov/Search/Crime/State/RunCrimeStatebyState.cfm
This dataset contains the population of the state and the number of incidents of violent crime which are classified as:
Violent Crime Total
Murder and Manslaughter
Legacy Rape
Revised Rape (the empty category)
Robbery
Aggravated Assault
The dataset was actually quite clean for the most part. I needed to remove the Revised rape column as it had been 
depracated and was no longer in use. I changed up a few of the column names to make them easier to read and work with.

```{r}

Crime_US <- read_excel("crimeAllStates.xlsx", skip=9)
colnames(Crime_US)[colnames(Crime_US) == "Revised rape /2"] <- "delete"
Crime_US <- subset(Crime_US, select = -c(delete))
colnames(Crime_US)[colnames(Crime_US) == "Legacy rape /1"] <- "Rape"
colnames(Crime_US)[colnames(Crime_US) == "Violent crime total"] <- "Violent_crime_total"
colnames(Crime_US)[colnames(Crime_US) == "Murder and nonnegligent Manslaughter"] <- "Murder_and_Manslaughter"
colnames(Crime_US)[colnames(Crime_US) == "Aggravated assault"] <- "Aggravated_assault"

```

The challenging part was splitting the large dataset up by state so that I could have state based models. I first created
a vector of States names.
The next step was to create an empty list which I will then fill in a loop. I know that each tibble for the state will
be 31 rows long so I set tracking variables m and n to make sure I get exactly the rows I need for each tibble. The for
loop goes the length of the state names vector and each time it makes a tibble from Crime_US using slice and then mutate
to add a name column. After the for loop I use the names function to name every element in the list after an element in
my state names vector. The function list2env then turns a list of tibbles into the global environment.

```{r}

states_vec <- c("Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "D.C.", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennslyvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming")

state_crime <- list() 
m <- 1
n <- 31

for (i in 1:length(states_vec)){

  state_crime[[i]] <- slice(Crime_US, m:n) %>%
                        mutate(state = states_vec[i])
  m <- (m + 39)
  n <- (n + 39) 
}

names(state_crime) <- states_vec

bind_rows(state_crime)

list2env(state_crime, .GlobalEnv)

```
